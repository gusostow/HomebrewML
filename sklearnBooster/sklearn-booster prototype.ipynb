{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier #default base estimator\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_classes * n_clusters_per_class must be smaller or equal 2 ** n_informative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-295-3b15dd701105>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflip_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters_per_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/envs/dsi/lib/python2.7/site-packages/sklearn/datasets/samples_generator.pyc\u001b[0m in \u001b[0;36mmake_classification\u001b[0;34m(n_samples, n_features, n_informative, n_redundant, n_repeated, n_classes, n_clusters_per_class, weights, flip_y, class_sep, hypercube, shift, scale, shuffle, random_state)\u001b[0m\n\u001b[1;32m    154\u001b[0m                          \" features\")\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mn_informative\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_clusters_per_class\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         raise ValueError(\"n_classes * n_clusters_per_class must\"\n\u001b[0m\u001b[1;32m    157\u001b[0m                          \" be smaller or equal 2 ** n_informative\")\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_classes * n_clusters_per_class must be smaller or equal 2 ** n_informative"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(flip_y=0.1, n_clusters_per_class=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, n_estimators):\n",
    "    \n",
    "    pt_weights = np.array([1. / X.shape[0] for _ in range(X.shape[0])])\n",
    "    estimator_weights = np.ones(n_estimators)\n",
    "    \n",
    "    estimators = [DecisionTreeClassifier(max_depth = 2) for _ in range(n_estimators)]\n",
    "    \n",
    "    for indx, estimator in enumerate(estimators):\n",
    "        \n",
    "        estimator.fit(X, y, sample_weight = pt_weights)\n",
    "        \n",
    "        wrong_points = estimator.predict(X) != y\n",
    "        wrong_points = wrong_points.astype(\"float\")\n",
    "        loss = np.sum(pt_weights * wrong_points) / np.sum(pt_weights)\n",
    "    \n",
    "        estimator_weight = np.log((1 - loss) / loss)\n",
    "        estimator_weights[indx] = estimator_weight\n",
    "        \n",
    "        pt_weights *= np.exp(estimator_weight * wrong_points)\n",
    "    \n",
    "    return estimators, estimator_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = lambda x: np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "class BoostedClassifier(object):\n",
    "    \n",
    "    def __init__(self, base_estimator, n_estimators):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.estimators = [clone(self.base_estimator) for _ in range(self.n_estimators)]\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "    \n",
    "        pt_weights = np.array([1. / X.shape[0] for _ in range(X.shape[0])])\n",
    "        estimator_weights = np.ones(self.n_estimators)\n",
    "        \n",
    "        pred = []\n",
    "        for indx, estimator in enumerate(self.estimators):\n",
    "            \n",
    "            train_ind = np.array(range(X.shape[0]))\n",
    "            train_ind_weighted = np.random.choice(train_ind,\\\n",
    "                                                  X.shape[0], p = pt_weights)\n",
    "            \n",
    "            X_weighted = X[train_ind_weighted]\n",
    "            y_weighted = y[train_ind_weighted]\n",
    "            \n",
    "            estimator.fit(X_weighted, y_weighted)\n",
    "            pred.append(estimator.predict(X))\n",
    "            \n",
    "            wrong_points = estimator.predict(X_weighted) != y_weighted\n",
    "            wrong_points = wrong_points.astype(\"float\")\n",
    "\n",
    "            loss = np.dot(wrong_points, pt_weights) / np.sum(pt_weights)\n",
    "            \n",
    "            if not loss: #prevent divide by zero \n",
    "                break\n",
    "            \n",
    "            estimator_weight = np.log((1-loss) / loss)\n",
    "            estimator_weights[indx] = estimator_weight\n",
    "\n",
    "            pt_weights *= np.exp(1 * estimator_weight * wrong_points)\n",
    "            pt_weights = softmax(pt_weights)\n",
    "        \n",
    "        self.estimator_weights = estimator_weights\n",
    "        self._pt_weights_ = pt_weights\n",
    "        self.pred = np.column_stack(pred)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        pred_matrix = np.column_stack([estimator.predict(X) for estimator in self.estimators])\n",
    "        pred_matrix[pred_matrix == 0] = -1\n",
    "        \n",
    "        raw_predictions = pred_matrix.dot(self.estimator_weights)\n",
    "        predictions = np.where(raw_predictions >= 0, 1, 0)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth = 1)\n",
    "\n",
    "boost = BoostedClassifier(dt, n_estimators=1)\n",
    "\n",
    "boost.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90000000000000002"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(boost.predict(X) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
