{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier #default base estimator\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(flip_y=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, n_estimators):\n",
    "    \n",
    "    pt_weights = np.array([1. / X.shape[0] for _ in range(X.shape[0])])\n",
    "    estimator_weights = np.ones(n_estimators)\n",
    "    \n",
    "    estimators = [DecisionTreeClassifier(max_depth = 2) for _ in range(n_estimators)]\n",
    "    \n",
    "    for indx, estimator in enumerate(estimators):\n",
    "        \n",
    "        estimator.fit(X, y, sample_weight = pt_weights)\n",
    "        \n",
    "        wrong_points = estimator.predict(X) != y\n",
    "        wrong_points = wrong_points.astype(\"float\")\n",
    "        loss = np.sum(pt_weights * wrong_points) / np.sum(pt_weights)\n",
    "    \n",
    "        estimator_weight = np.log((1 - loss) / loss)\n",
    "        estimator_weights[indx] = estimator_weight\n",
    "        \n",
    "        pt_weights *= np.exp(estimator_weight * wrong_points)\n",
    "    \n",
    "    return estimators, estimator_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = lambda x: np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "class BoostedClassifier(object):\n",
    "    \n",
    "    def __init__(self, base_estimator, n_estimators):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.estimators = [clone(self.base_estimator) for _ in range(self.n_estimators)]\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "    \n",
    "        pt_weights = np.array([1. / X.shape[0] for _ in range(X.shape[0])])\n",
    "        estimator_weights = np.ones(self.n_estimators)\n",
    "        \n",
    "        pred = []\n",
    "        for indx, estimator in enumerate(self.estimators):\n",
    "            \n",
    "            train_ind = np.array(range(X.shape[0]))\n",
    "            train_ind_weighted = np.random.choice(train_ind,\\\n",
    "                                                  X.shape[0], p = pt_weights)\n",
    "            \n",
    "            X_weighted = X[train_ind_weighted]\n",
    "            y_weighted = y[train_ind_weighted]\n",
    "            \n",
    "            estimator.fit(X_weighted, y_weighted)\n",
    "            pred.append(estimator.predict(X))\n",
    "            \n",
    "            wrong_points = estimator.predict(X_weighted) != y_weighted\n",
    "            wrong_points = wrong_points.astype(\"float\")\n",
    "\n",
    "            loss = np.dot(wrong_points, pt_weights) / np.sum(pt_weights)\n",
    "            \n",
    "            if not loss: #prevent divide by zero \n",
    "                break\n",
    "            \n",
    "            estimator_weight = np.log((1-loss) / loss)\n",
    "            estimator_weights[indx] = estimator_weight\n",
    "\n",
    "            pt_weights *= np.exp(1 * estimator_weight * wrong_points)\n",
    "            pt_weights = softmax(pt_weights)\n",
    "        \n",
    "        self.estimator_weights = estimator_weights\n",
    "        self._pt_weights_ = pt_weights\n",
    "        self.pred = np.column_stack(pred)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        pred_matrix = np.column_stack([estimator.predict(X) for estimator in self.estimators])\n",
    "        pred_matrix[pred_matrix == 0] = -1\n",
    "        \n",
    "        raw_predictions = pred_matrix.dot(self.estimator_weights)\n",
    "        predictions = np.where(raw_predictions >= 0, 1, 0)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth = 1)\n",
    "\n",
    "boost = BoostedClassifier(dt, n_estimators=1)\n",
    "\n",
    "boost.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90000000000000002"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(boost.predict(X) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
